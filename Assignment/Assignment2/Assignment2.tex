\documentclass{article}
\usepackage{hyperref}
\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{lmodern}
\usepackage[left=0.25in, right=0.25in, top=0.75in, bottom=0.75in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage{tcolorbox}
\usepackage{fancyhdr}
\usepackage{cancel}
\usepackage{placeins}
\usepackage{multirow}
\usepackage{algorithm2e}
\usepackage{booktabs}
\usepackage{bbding}
%\pagecolor{black}
%\color{white}
\pagecolor{white}
\color{black}
\pagestyle{fancy}

\hypersetup{%
  colorlinks=true,% hyperlinks will be black
  linkbordercolor=red,% hyperlink borders will be red
  pdfborderstyle={/S/U/W 1}% border style will be underline of width 1pt
}

\newcommand{\soln}{\\ \textbf{Solution}: }
\newcommand{\bkt}[1]{\left(#1\right)}

\lhead{MA5892: Numerical Methods and Scientific Computing}
\chead{Assignment: 2}
\rhead{Rollnumber: PH15M015}

\begin{document}
\begin{enumerate}
\item Consider the Vandermonde matrix $V$, i.e.,

    $$ V = 
    \begin{bmatrix}
        1 & x_{0} & x_{0}^{2} & . & . & . & x_{0}^{n}\\
        1 & x_{1} & x_{1}^{2} & . & . & . & x_{1}^{n}\\
        1 & x_{2} & x_{2}^{2} & . & . & . & x_{2}^{n}\\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        1 & x_{n} & x_{n}^{2} & . & . & . & x_{n}^{n} 
    \end{bmatrix}
    $$



\begin{enumerate}[(a)]  
\item Show that $det(V)$ is a polynomial in the variables $x_{0}, x_{1}, ..., x_{n}$ with degree $\displaystyle \frac{n(n+1)}{2}$ \\

\textbf{Solution:}

        The Vandermonde determinant $det(V) \neq 0$ if and only if the variables $x_{0}, x_{1}, ..., x_{n}$ are distinct.

        Let $n = 2$, then,

        \begin{align*}
        V &= \begin{bmatrix}
            1 & x_{0} & x_{0}^{2}\\
            1 & x_{1} & x_{1}^{2}\\
            1 & x_{2} & x_{2}^{2}
        \end{bmatrix} \\ \\
        det(V) &= \begin{vmatrix}
            1 & x_{0} & x_{0}^{2}\\
            1 & x_{1} & x_{1}^{2}\\
            1 & x_{2} & x_{2}^{2}
        \end{vmatrix} \\ \\
        &= 1(x_{1} x_{2}^{2} - x_{1}^{2} x_{2}) - x_{0}(x_{2}^{2} - x_{1}^{2}) + x_{0}^{2}(x_{2} - x_{1}) \\
        &= x_{1} x_{2}^{2} - x_{1}^{2} x_{2} - x_{0} x_{2}^{2} + x_{0} x_{1}^{2} + x_{0}^{2} x_{2} - x_{1} x_{0}^{2} \\
        &= x_{1} x_{2}^{2} - x_{1}^{2} x_{2} - x_{0} x_{2}^{2} + x_{0} x_{1} x_{2} - x_{1} x_{2} x_{0} + x_{1}^{2} x_{0} + x_{0}^{2} x_{2} - x_{0}^{2} x_{1} \\
        &= (x_{1} x_{2} - x_{1}^{2} - x_{0} x_{2} + x_{0} x_{1}) (x_{2} - x_{0}) \\
        &= (x_{1} - x_{0}) (x_{2} - x_{1}) (x_{2} - x_{0}) \\
        &= \displaystyle \prod_{0 \leq j < i \leq 2} (x_{i} - x_{j}) 
        \end{align*}


\item Show that if $x_{i} = x_{j}$ for $i \neq j$, then $det(V) = 0$ \\

\textbf{Solution:}

        The Vandermonde determinant $det(V) \neq 0$ if and only if the variables $x_{0}, x_{1}, ..., x_{n}$ are distinct.

        Let $n = 1$, then,

        \begin{align*}
        det(V) &= \begin{vmatrix}
            1 & x_{0} \\
            1 & x_{1} \\
        \end{vmatrix} \\ \\
            &= (x_{1} - x_{0}) \\
            &= 0 \hspace{1cm} if \hspace{0.2cm} x_{1} = x_{0}
        \end{align*}

        In general, for degree n,

        \begin{align*}
            det(V) &= \displaystyle \prod_{0 \leq j < i \leq n} (x_{i} - x_{j}) \\
            &= 0 \hspace{1cm} if \hspace{0.2cm} x_{i} = x_{j}
        \end{align*}



\item Conclude that $(x_{i} - x_{j})$ is a factor of $det(V)$ \\

\textbf{Solution:}
Since $det(V)$ is a polynomial, this implies that $(x_{i} - x_{j})$ is a factor of $det(V)$.


\item Conclude that $det(V) = C \left(\displaystyle \prod_{0 \leq j < i \leq n} (x_{i} - x_{j}) \right)$, where $C$ is a constant \\

\textbf{Solution:}

    \begin{align*}
    V &= \begin{bmatrix}
        1 & x_{0} & x_{0}^{2} & . & . & . & x_{0}^{n}\\
        1 & x_{1} & x_{1}^{2} & . & . & . & x_{1}^{n}\\
        1 & x_{2} & x_{2}^{2} & . & . & . & x_{2}^{n}\\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        1 & x_{n} & x_{n}^{2} & . & . & . & x_{n}^{n} 
    \end{bmatrix} \\ \\
    det(V) &= det \begin{bmatrix}
        1 & x_{0} & x_{0}^{2} & . & . & . & x_{0}^{n}\\
        1 & x_{1} & x_{1}^{2} & . & . & . & x_{1}^{n}\\
        1 & x_{2} & x_{2}^{2} & . & . & . & x_{2}^{n}\\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        . & .     & .         & . & . & . & . \\
        1 & x_{n} & x_{n}^{2} & . & . & . & x_{n}^{n} 
    \end{bmatrix}
    \end{align*}

    \begin{align*}
    \text{then, by row operations we get} \\ \\
        &= det \begin{bmatrix}
            1 & x_{0} & x_{0}^{1} & . & . & . & x_{0}^{n-1} & x_{0}^{n}\\
            0 & x_{1} - x_{0} & x_{1}^{2} - x_{0}^{2} & . & . & . & x_{1}^{n-1} - x_{0}^{n-1} & x_{1}^{n} - x_{0}^{n}\\
            . & . & . & . & . & . & . & . \\
            . & . & . & . & . & . & . & . \\
            . & . & . & . & . & . & . & . \\
            0 & x_{n} - x_{0} & x_{n}^{2} - x_{0}^{2} & . & . & . & x_{n}^{n-1} - x_{0}^{n-1} & x_{n}^{n} - x_{0}^{n}
        \end{bmatrix}_{n+1 \times n+1} \\ \\
        &= det \begin{bmatrix}
            x_{1} - x_{0} & x_{1}^{2} - x_{0}^{2} & . & . & . & x_{1}^{n-1} - x_{0}^{n-1} & x_{1}^{n} - x_{0}^{n}\\
            x_{2} - x_{1} & x_{2}^{2} - x_{1}^{2} & . & . & . & x_{2}^{n-1} - x_{1}^{n-1} & x_{2}^{n} - x_{1}^{n}\\
            . & . & . & . & . & . & . \\
            . & . & . & . & . & . & . \\
            x_{n} - x_{0} & x_{n}^{2} - x_{0}^{2} & . & . & . & x_{n}^{n-1} - x_{0}^{n-1} & x_{n}^{n} - x_{0}^{n}
        \end{bmatrix}_{n \times n} \\ \\
        &= det \begin{bmatrix}
            x_{1} - x_{0} & 0 & . & . & . & 0\\
            0 & x_{2} - x_{0} & . & . & . & 0\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            0 & 0 & . & . & . & x_{n} - x_{0}
        \end{bmatrix}
        \begin{bmatrix}
            1 & x_{1} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{1}^{n-1-i} x_{0}^{i}\\
            1 & x_{2} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{2}^{n-1-i} x_{0}^{i}\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            1 & x_{n} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{n}^{n-1-i} x_{0}^{i}
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        \text{and, by Cauchy's Theorem, we get that} \\ \\
        &= \displaystyle \prod_{j=1}^{n} (x_{j} - x_{0}) \ \ det \begin{bmatrix}
            1 & x_{1} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{1}^{n-1-i} x_{0}^{i}\\
            1 & x_{2} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{2}^{n-1-i} x_{0}^{i}\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            . & . & . & . & . & .\\
            1 & x_{n} + x_{0} & . & . & . & \sum_{i=0}^{n-1} x_{n}^{n-1-i} x_{0}^{i}
        \end{bmatrix} \\ \\
        &= \displaystyle \prod_{j=1}^{n} (x_{j} - x_{0}) \  \ det \begin{bmatrix}
            1 & x_{1} & x_{1}^{2} & . & . & . & x_{1}^{n-1}\\
            1 & x_{2} & x_{2}^{2} & . & . & . & x_{2}^{n-1}\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            1 & x_{1} & x_{n}^{2} & . & . & . & x_{n}^{n-1}
        \end{bmatrix}
        \begin{bmatrix}
            1 & x_{0} & x_{0}^{2} & . & . & . & x_{0}^{n-1}\\
            0 & 1 & x_{0} & . & . & . & x_{0}^{n-2}\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            0 & 0 & 0 & . & . & . & 1
        \end{bmatrix} \\ \\
        \text{again, by Cauchy, we have that} \\ \\
        &= \displaystyle \prod_{j=1}^{n} (x_{j} - x_{0}) \  \ det \begin{bmatrix}
            1 & x_{1} & x_{1}^{2} & . & . & . & x_{1}^{n-1}\\
            1 & x_{2} & x_{2}^{2} & . & . & . & x_{2}^{n-1}\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            . & . & . & . & . & . & .\\
            1 & x_{n} & x_{n}^{2} & . & . & . & x_{n}^{n-1}
        \end{bmatrix} \\ \\
        &= \displaystyle \prod_{j=1}^{n} (x_{j} - x_{0}) \  \ \prod_{1 \leq i < j \leq n} (x_{j} - x_{i}) \\ \\
        &= \displaystyle \prod_{0 \leq i < j \leq n} (x_{j} - x_{i})
    \end{align*}



\item Compare the coefficient of $x_{1} \hspace{1mm} x_{2}^{2} \hspace{1mm} x_{3}^{3} \hspace{1mm} ... \hspace{1mm} x_{n}^{n}$ to obtain the value of $C$ \\

\textbf{Solution:}
The coefficient of the leading diagonal, $\displaystyle \prod_{n} x_{n}^{n}$ is equals to $1$ in both the determinant and the product, the value of $C = 1$.
\end{enumerate}






\item Monic Legendre polynomials on $[-1, 1]$ are defined as follows:
    $$ q_{0}(x) = 1 $$
    $$ q_{1}(x) = x $$

and $q_{n}(x)$ is a monic polynomial of degree $n$ such that $\displaystyle \int_{-1}^{1} q_{n}(x) q_{m}(x) dx = 0 $ for all $m \neq n$.

\begin{enumerate}[(a)]
\item Show that these orthogonal polynomials satisfy
    $$q_{n+1}(x) = x q_{n}(x) - \left(\frac{n^{2}}{4n^{2} - 1} \right) q_{n-1}(x)$$ \\

\textbf{Solution:}

let $n = 1$, 

        \begin{align*}
            q_{2}(x) &= x q_{1}(x) - \left(\frac{1}{4 - 1}\right) q_{0}(x) \\
            &= x(x) - \left(\frac{1}{3}\right) (1) \\
            &= x^{2} - \left(\frac{1}{3}\right) \\
            &= 3x^{2} - 1
        \end{align*}

\item Prove that if $p(x)$ is a monic polynomial of degree $n$ minimizing $||p(x)||_{2}$, then $p(x) = q_{n}(x)$ \\

\textbf{Solution:}



\item Conclude that the Legendre nodes (i.e., the roots of the Legendre polynomial) minimize $\displaystyle \int_{-1}^{1} \left( \prod_{k=0}^{n} (x-x_{k}) \right)^{2} dx$ \\

\textbf{Solution:}




\end{enumerate}


\item The Chebyshev polynomials of the first kind are defined as
    $$T_{n}(x) = cos(n \ arccos(x))$$

\begin{enumerate}[(a)]
\item Show that the Chebyshev polynomials satisfy the orthogonality condition
    $$\displaystyle \int_{-1}^{1} \frac{T_{n}(x) T_{m}(x)}{\sqrt{1 - x^{2}}} dx = 0$$

\item Show that the Chebyshev polynomials of the first kind satisfy the recurrence:
    $$T_{n+1} = 2xT_{n} - T_{n-1}$$
with $T_{0}(x) = 1$ and $T_{1}(x) = x$.

\item Show that $T_{n}(x)$ is a polynomial of degree $n$ with leading coefficient as $2^{n-1}$ for $n \geq 1$

\item All zeros of $T_{n+1}(x)$ are in the interval $[-1, 1]$ and given by $x_{k} = cos \left( \displaystyle \frac{2k+1}{2n+2} \pi \right)$, where $k \in \{0,1,2,...,n\}$

\item Conclude that $T_{n}(x)$ alternates between $+1$ and $-1$ exactly $n+1$ times
\item Show that
    $$\displaystyle \left| \prod_{k=0}^{n} (x - x_{k}) \right| \leq \frac{1}{2^{n}}$$
for all $x \in [-1, 1]$


\item For any choice of nodes $\{y_{k}\}_{k=0}^{n}$, consider the polynomial $P_{n+1}(x) = \displaystyle \prod_{k=0}^{n} (x - y_{k})$ and look at $F(x) = P_{n+1}(x) -
    \displaystyle \frac{T_{n+1}(x)}{2^{n}}$ \\

If $\displaystyle |P_{n+1}(x)| \leq  \frac{1}{2^{n}}$, show that $F(x)$ alternates in sign $n+2$ times on the interval $[-1, 1]$. Hence, conclude that $F(x)$ has to be identically zero and 
therefore conclude that Chebyshev nodes of the first kind minimizes $max \ x \in [-1, 1] \  \left| \displaystyle \prod_{k=0}^{n} (x - x_{k}) \right|$
\end{enumerate}

\item Consider the uniformly spaced nodes, the Legendre nodes, Chebyshev nodes of the first kind for $n+1$ points. For all these sets of points, perform the following:

\begin{enumerate}[(a)]
\item Plot the condition number of the Vandermonde matrix as a function of $n$ (Use semilogy for plot). Comment on how the condition number scales with $n$ for all these three sets of nodes. You will get three curves (one corresponding to uniform nodes, one corresponding to Legendre nodes and another one corresponding to Chebyshev nodes).
\item For the Range function obtain the and plot the interpolant by the three set of nodes for $n \in \{5,7,9,...,33,35\}$ by

\begin{itemize}
\item Solving the linear system
\item Using Lagrange polynomials
\end{itemize}

Comment on the above.

\item Plot the decay in maximum relative error as a function of $n$ (on a semilogy) plot for the three different interpolants (vary $n$ from $5$ to $35$ in steps of $2$). To get the maximum relative error, evaluate the interpolant and the Runge function at $1001$ equally spaced points and compute the maximum relative error at these $1001$ points.

\end{enumerate}

\item Show that for any set of interpolant nodes, we have

    $$\displaystyle \sum_{j=0}^{n} x_{j}^{m} l_{j}(x) = x^{m} $$

for all $m \in \{0,1,...,n\}$, where $l_{j}(x)$ is the $j^{th}$ Lagrange polynomial.
\end{enumerate}
\end{document}
